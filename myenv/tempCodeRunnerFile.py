for i in corpus:
#     words=nltk.word_tokenize(i)
#     for word in words:
#         if word not in set(stopwords.words('english')):     #applying english stopwords
#             # print(stemmer.stem(word))
#             print(lemmatizer.lemmatize(word))